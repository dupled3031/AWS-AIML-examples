{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Personalize boto3 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBucket(bucketname):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_buckets()\n",
    "    existingbuckets = [d['Name'] for d in response[\"Buckets\"]]\n",
    "    #print(existingbuckets)\n",
    "    if bucketname not in existingbuckets:\n",
    "        print(\"creating bucket \" + bucketname)\n",
    "        s3.create_bucket(Bucket=bucketname)\n",
    "    else:\n",
    "        print(\"bucket exists! \" + bucketname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Specify a Bucket and Data Output Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket exists! aimlbootcamp485483564801\n"
     ]
    }
   ],
   "source": [
    "accountid = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket = \"aimlbootcamp\" + accountid\n",
    "\n",
    "createBucket(bucket)\n",
    "\n",
    "#bucket = \"personalize-demo\"       # replace with the name of your S3 bucket\n",
    "filename = \"movie-lens-100k.csv\"  # replace with a name that you want to save the dataset under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download, Prepare, and Upload Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-03 13:45:45--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File ‘ml-100k.zip’ not modified on server. Omitting download.\n",
      "\n",
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       USER_ID  ITEM_ID  RATING  TIMESTAMP\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "...        ...      ...     ...        ...\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['RATING'] > 3.6]                # keep only movies rated 3.6 and above\n",
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] # select columns that match the columns in the schema below\n",
    "data.to_csv(filename, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createschema(schema, name):\n",
    "    \n",
    "    response = personalize.list_schemas(\n",
    "        maxResults=100\n",
    "    )\n",
    "\n",
    "    print(\"response: \", response)\n",
    "    \n",
    "    for item in response[\"schemas\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            return item[\"schemaArn\"]\n",
    "\n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name = name,\n",
    "        schema = json.dumps(schema)\n",
    "    )\n",
    "\n",
    "    schema_arn = create_schema_response['schemaArn']\n",
    "    #print(json.dumps(create_schema_response, indent=2))\n",
    "    return schema_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  {'schemas': [{'name': 'DEMO-schema', 'schemaArn': 'arn:aws:personalize:us-east-1:485483564801:schema/DEMO-schema', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 31, 53, 455000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 31, 53, 455000, tzinfo=tzlocal())}, {'name': 'aimlbootcamp-DEMO-schema', 'schemaArn': 'arn:aws:personalize:us-east-1:485483564801:schema/aimlbootcamp-DEMO-schema', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 52, 49, 340000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 52, 49, 340000, tzinfo=tzlocal())}, {'name': 'aimlbootcamp-schema-personalize-20191102', 'schemaArn': 'arn:aws:personalize:us-east-1:485483564801:schema/aimlbootcamp-schema-personalize-20191102', 'creationDateTime': datetime.datetime(2019, 11, 2, 13, 49, 3, 99000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 13, 49, 3, 99000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': 'e3ca9548-949a-4a51-a4af-9f082bf1237a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Sun, 03 Nov 2019 13:45:46 GMT', 'x-amzn-requestid': 'e3ca9548-949a-4a51-a4af-9f082bf1237a', 'content-length': '617', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "schema_arn:  arn:aws:personalize:us-east-1:485483564801:schema/aimlbootcamp-schema-personalize-20191102\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "schema_arn = createschema(schema, \"aimlbootcamp-schema-personalize-20191102\")\n",
    "print(\"schema_arn: \", schema_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Dataset Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdatasetGroup(name):\n",
    "    response = personalize.list_dataset_groups(\n",
    "        maxResults=100\n",
    "    )\n",
    "    print(\"response: \", response)\n",
    "    \n",
    "    for item in response[\"datasetGroups\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            return item[\"datasetGroupArn\"]\n",
    "    create_dataset_group_response = personalize.create_dataset_group(\n",
    "        name = name\n",
    "    )\n",
    "\n",
    "    dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "    #print(json.dumps(create_dataset_group_response, indent=2))   \n",
    "    return dataset_group_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  {'datasetGroups': [{'name': 'DEMO-dataset-group', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/DEMO-dataset-group', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 31, 53, 504000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 32, 22, 889000, tzinfo=tzlocal())}, {'name': 'aimlbootcamp-20191102', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/aimlbootcamp-20191102', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 13, 49, 3, 173000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 13, 49, 26, 165000, tzinfo=tzlocal())}, {'name': 'aimldatasetgroupname', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/aimldatasetgroupname', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 56, 51, 110000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 57, 19, 831000, tzinfo=tzlocal())}, {'name': 'daniel', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/daniel', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 7, 7, 2, 39, 9, 916000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 7, 7, 2, 39, 30, 409000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': '2718894f-6c18-4ea2-ab89-f7c28a69bcff', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Sun, 03 Nov 2019 13:45:46 GMT', 'x-amzn-requestid': '2718894f-6c18-4ea2-ab89-f7c28a69bcff', 'content-length': '880', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "dataset_group_arn:  arn:aws:personalize:us-east-1:485483564801:dataset-group/aimlbootcamp-20191102\n"
     ]
    }
   ],
   "source": [
    "dataset_group_arn = createdatasetGroup(\"aimlbootcamp-20191102\")\n",
    "print(\"dataset_group_arn: \", dataset_group_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Group to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataset(name, dataset_type, dataset_group_arn, schema_arn):\n",
    "    response = personalize.list_datasets(\n",
    "        datasetGroupArn=dataset_group_arn,\n",
    "        maxResults=100\n",
    "    )\n",
    "    \n",
    "    #print(\"response: \", response)\n",
    "    for item in response[\"datasets\"]:\n",
    "        print(\"inspecting: \", item)\n",
    "        if item[\"name\"] == name or item[\"datasetType\"] == dataset_type:\n",
    "            #return item[\"datasetArn\"]\n",
    "            response = personalize.delete_dataset(\n",
    "                datasetArn=item[\"datasetArn\"]\n",
    "            )\n",
    "            max_time = time.time() + 2*60 # 10 minutes\n",
    "            while time.time() < max_time:\n",
    "                try:\n",
    "                    response = personalize.describe_dataset(datasetArn=item[\"datasetArn\"])\n",
    "                except Exception as e:\n",
    "                    if \"ResourceNotFoundException\".lower() in str(e).lower():\n",
    "                        print(\"delete completed\")\n",
    "                        break\n",
    "                except:\n",
    "                    raise\n",
    "                                    \n",
    "                status = response[\"dataset\"][\"status\"]\n",
    "                print(\"DatasetGroup: {}\".format(status))\n",
    "\n",
    "                time.sleep(5)\n",
    "            \n",
    "            \n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name = name,\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = schema_arn\n",
    "    )\n",
    "    print(\"dataset created....\")\n",
    "    dataset_arn = create_dataset_response['datasetArn']\n",
    "    #print(json.dumps(create_dataset_response, indent=2))\n",
    "    return dataset_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspecting:  {'name': 'aiml-bootcamp-dataset-20191102', 'datasetArn': 'arn:aws:personalize:us-east-1:485483564801:dataset/aimlbootcamp-20191102/INTERACTIONS', 'datasetType': 'INTERACTIONS', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 3, 1, 29, 32, 246000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 3, 1, 29, 32, 246000, tzinfo=tzlocal())}\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "delete completed\n",
      "dataset created....\n",
      "datasetarn:  arn:aws:personalize:us-east-1:485483564801:dataset/aimlbootcamp-20191102/INTERACTIONS\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "dataset_arn = createdataset(\"aiml-bootcamp-dataset-20191102\", dataset_type, dataset_group_arn, schema_arn)\n",
    "\n",
    "\n",
    "print(\"datasetarn: \", dataset_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare, Create, and Wait for Dataset Import Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach Policy to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicyBootcamp\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicyAIMLBootcamp\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "policycreateresponse = s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Personalize Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPersonalizeIAMRole(role_name):\n",
    "    iam = boto3.client(\"iam\")\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "              },\n",
    "              \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    #print(\"response: \", response)\n",
    "    #return\n",
    "    try:\n",
    "        create_role_response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "        )\n",
    "        role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "    except Exception as e:\n",
    "        if \"EntityAlreadyExists\".lower() in str(e).lower():\n",
    "            print(\"the role already exists!\")\n",
    "            response = iam.list_roles(\n",
    "                PathPrefix=\"/\",\n",
    "                MaxItems=1000\n",
    "            )\n",
    "            #print(\"all roles: \", response)\n",
    "            for item in response[\"Roles\"]:\n",
    "                if item[\"RoleName\"] == role_name:\n",
    "                    role_arn = item[\"Arn\"]\n",
    "                    break\n",
    "                    \n",
    "    except:\n",
    "        raise\n",
    "\n",
    "    # AmazonPersonalizeFullAccrole_arness provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "    # if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "    # that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "    policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "    iam.attach_role_policy(\n",
    "        RoleName = role_name,\n",
    "        PolicyArn = policy_arn\n",
    "    )\n",
    "    policy_arn = \"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    "    iam.attach_role_policy(\n",
    "        RoleName = role_name,\n",
    "        PolicyArn = policy_arn\n",
    "    )   \n",
    "    print(\"pausing execution to allow for IAM role propagation.....\")\n",
    "    time.sleep(30) # wait to allow IAM role policy attachment to propagate\n",
    "\n",
    "    return role_arn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the role already exists!\n",
      "pausing execution to allow for IAM role propagation.....\n",
      "arn:aws:iam::485483564801:role/PersonalizeRoleAIMLBootcamp-imports-2\n"
     ]
    }
   ],
   "source": [
    "role_name = \"PersonalizeRoleAIMLBootcamp-imports-2\"\n",
    "role_arn = createPersonalizeIAMRole(role_name)\n",
    "#json.dumps(create_dataset_response, indent=2)\n",
    "print(role_arn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-1:485483564801:dataset-import-job/bootcamp-dataset-import-job-2\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"05041644-61cb-49b4-a2fb-fb899ca1a68f\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sun, 03 Nov 2019 13:46:47 GMT\",\n",
      "      \"x-amzn-requestid\": \"05041644-61cb-49b4-a2fb-fb899ca1a68f\",\n",
      "      \"content-length\": \"117\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"bootcamp-dataset-import-job-2\",\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket, filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Import Job to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** 2019-11-03 14:03:20.680181  DatasetImportJob: ACTIVE                             \r"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "showme = \" \"\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(showme, datetime.datetime.now(), \" DatasetImportJob: {}\".format(status), \"             \", end='\\r')\n",
    "    showme += \"*\"\n",
    "    if len(showme)> 10:\n",
    "        showme = \" \"\n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(3.5719)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'name': 'aws-hrnn',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-coldstart',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-coldstart',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-metadata',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-metadata',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-personalized-ranking',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-personalized-ranking',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-popularity-count',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-popularity-count',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-sims',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-sims',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': 'e9da6aba-96d1-4b38-bc01-3996f8c14ebe',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 03 Nov 2019 14:03:20 GMT',\n",
       "   'x-amzn-requestid': 'e9da6aba-96d1-4b38-bc01-3996f8c14ebe',\n",
       "   'content-length': '1067',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_recipes_response = personalize.list_recipes()\n",
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-hrnn\" # aws-hrnn selected for demo purposes\n",
    "list_recipes_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSolution(name, dataset_group_arn, recipe_arn):\n",
    "    response = personalize.list_solutions(\n",
    "        datasetGroupArn=dataset_group_arn,\n",
    "        maxResults=100\n",
    "    )\n",
    "    #print(response)\n",
    "    for item in response[\"solutions\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            print(\"solution with the same name already exists. Deleting the existing one.\")\n",
    "            try:\n",
    "                response = personalize.delete_solution(solutionArn=item[\"solutionArn\"])\n",
    "            except Exception as e:\n",
    "                if \"ResourceInUseException\".lower() in str(e).lower():\n",
    "                    print(\"delete failed as resource is in use\")\n",
    "            except:\n",
    "                raise\n",
    "        \n",
    "            return createSolution(name+\"1\", dataset_group_arn, recipe_arn) #delete old one. create new one with a new name \n",
    "            \n",
    "    create_solution_response = personalize.create_solution(\n",
    "        name = name,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        recipeArn = recipe_arn\n",
    "    )\n",
    "\n",
    "    solution_arn = create_solution_response['solutionArn']\n",
    "    #print(json.dumps(create_solution_response, indent=2))\n",
    "    return solution_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution with the same name already exists. Deleting the existing one.\n",
      "delete failed as resource is in use\n",
      "solution with the same name already exists. Deleting the existing one.\n",
      "solution with the same name already exists. Deleting the existing one.\n",
      "delete failed as resource is in use\n",
      "arn:aws:personalize:us-east-1:485483564801:solution/aimlbootcampExampleSolution111\n"
     ]
    }
   ],
   "source": [
    "solution_arn = createSolution(\"aimlbootcampExampleSolution\", dataset_group_arn, recipe_arn)\n",
    "print(solution_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:485483564801:solution/aimlbootcampExampleSolution111/8a9af355\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"04f2f57f-7e12-41fd-a592-1178f0da1915\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sun, 03 Nov 2019 14:03:20 GMT\",\n",
      "      \"x-amzn-requestid\": \"04f2f57f-7e12-41fd-a592-1178f0da1915\",\n",
      "      \"content-length\": \"116\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Solution Version to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-03 14:46:23.949985  Solution Version Status: ACTIVE                          \r"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(datetime.datetime.now(), \" Solution Version Status: {}\".format(status), \"             \", end='\\r')\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Metrics of Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"solutionVersionArn\": \"arn:aws:personalize:us-east-1:485483564801:solution/aimlbootcampExampleSolution111/8a9af355\",\n",
      "  \"metrics\": {\n",
      "    \"coverage\": 0.2769,\n",
      "    \"mean_reciprocal_rank_at_25\": 0.0388,\n",
      "    \"normalized_discounted_cumulative_gain_at_10\": 0.0471,\n",
      "    \"normalized_discounted_cumulative_gain_at_25\": 0.0666,\n",
      "    \"normalized_discounted_cumulative_gain_at_5\": 0.0393,\n",
      "    \"precision_at_10\": 0.0067,\n",
      "    \"precision_at_25\": 0.0058,\n",
      "    \"precision_at_5\": 0.009\n",
      "  },\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"3d9a7e8e-f717-403f-bcdf-76c60f0a0f78\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sun, 03 Nov 2019 14:46:23 GMT\",\n",
      "      \"x-amzn-requestid\": \"3d9a7e8e-f717-403f-bcdf-76c60f0a0f78\",\n",
      "      \"content-length\": \"413\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createcampaign(name, solutionVersionArn):\n",
    "\n",
    "    response = personalize.list_campaigns(\n",
    "        solutionArn=solutionVersionArn,\n",
    "        maxResults=100\n",
    "    )\n",
    "    #print(response)\n",
    "\n",
    "    for item in response[\"campaigns\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            print(\"campaign already exists (deleting): \", name)\n",
    "            response = personalize.delete_campaign(campaignArn=item[\"campaignArn\"])\n",
    "            return createcampaign(name+\"1\", solutionVersionArn) #recursively create/delete until no more collisions\n",
    "\n",
    "    try:\n",
    "        create_campaign_response = personalize.create_campaign(\n",
    "            name = name,\n",
    "            solutionVersionArn = solution_version_arn,\n",
    "            minProvisionedTPS = 1\n",
    "        )\n",
    "    except Exception as e:\n",
    "        if \"ResourceAlreadyExistsException\".lower() in str(e).lower():\n",
    "            return createcampaign(name+\"1\", solutionVersionArn) #try recursively\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "    campaign_arn = create_campaign_response['campaignArn']\n",
    "    #print(json.dumps(create_campaign_response, indent=2))\n",
    "    print(\"created new campaign: \", name, campaign_arn)\n",
    "    return campaign_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Campaign to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new campaign:  aimlbootcampcampaign111 arn:aws:personalize:us-east-1:485483564801:campaign/aimlbootcampcampaign111\n",
      "arn:aws:personalize:us-east-1:485483564801:campaign/aimlbootcampcampaign111\n"
     ]
    }
   ],
   "source": [
    "campaign_arn = createcampaign(\"aimlbootcampcampaign\", solution_version_arn)\n",
    "print(campaign_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campaign: CREATE PENDING\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: CREATE IN_PROGRESS\n",
      "Campaign: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a User and an Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: 532\n",
      "ITEM: Dragonheart (1996)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ITEM_ID                                      TITLE\n",
       "0           2                           GoldenEye (1995)\n",
       "1           3                          Four Rooms (1995)\n",
       "...       ...                                        ...\n",
       "1679     1681                        You So Crazy (1994)\n",
       "1680     1682  Scream of Stone (Schrei aus Stein) (1991)\n",
       "\n",
       "[1681 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|', usecols=[0,1], encoding='latin-1')\n",
    "items.columns = ['ITEM_ID', 'TITLE']\n",
    "\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "item_title = items.loc[items['ITEM_ID'] == item_id].values[0][-1]\n",
    "print(\"USER: {}\".format(user_id))\n",
    "print(\"ITEM: {}\".format(item_title))\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GetRecommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [\n",
      "  \"Bram Stoker's Dracula (1992)\",\n",
      "  \"Muriel's Wedding (1994)\",\n",
      "  \"Beauty and the Beast (1991)\",\n",
      "  \"Fish Called Wanda, A (1988)\",\n",
      "  \"Princess Bride, The (1987)\",\n",
      "  \"Willy Wonka and the Chocolate Factory (1971)\",\n",
      "  \"Dances with Wolves (1990)\",\n",
      "  \"Sound of Music, The (1965)\",\n",
      "  \"Snow White and the Seven Dwarfs (1937)\",\n",
      "  \"Clueless (1995)\",\n",
      "  \"Ace Ventura: Pet Detective (1994)\",\n",
      "  \"Indiana Jones and the Last Crusade (1989)\",\n",
      "  \"Fargo (1996)\",\n",
      "  \"Dave (1993)\",\n",
      "  \"Hunt for Red October, The (1990)\",\n",
      "  \"Remains of the Day, The (1993)\",\n",
      "  \"Heathers (1989)\",\n",
      "  \"Last of the Mohicans, The (1992)\",\n",
      "  \"Sleepless in Seattle (1993)\",\n",
      "  \"That Thing You Do! (1996)\",\n",
      "  \"Don Juan DeMarco (1995)\",\n",
      "  \"Mask, The (1994)\",\n",
      "  \"Blues Brothers, The (1980)\",\n",
      "  \"Pretty Woman (1990)\",\n",
      "  \"Cinderella (1950)\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    itemId = str(item_id)\n",
    ")\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "title_list = [items.loc[items['ITEM_ID'] == np.int(item['itemId'])].values[0][-1] for item in item_list]\n",
    "\n",
    "print(\"Recommendations: {}\".format(json.dumps(title_list, indent=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
