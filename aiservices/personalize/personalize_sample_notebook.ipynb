{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Personalize boto3 Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBucket(bucketname):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_buckets()\n",
    "    existingbuckets = [d['Name'] for d in response[\"Buckets\"]]\n",
    "    #print(existingbuckets)\n",
    "    if bucketname not in existingbuckets:\n",
    "        print(\"creating bucket \" + bucketname)\n",
    "        s3.create_bucket(Bucket=bucketname)\n",
    "    else:\n",
    "        print(\"bucket exists! \" + bucketname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Specify a Bucket and Data Output Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket exists! aimlbootcamp485483564801\n"
     ]
    }
   ],
   "source": [
    "accountid = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket = \"aimlbootcamp\" + accountid\n",
    "\n",
    "createBucket(bucket)\n",
    "\n",
    "#bucket = \"personalize-demo\"       # replace with the name of your S3 bucket\n",
    "filename = \"movie-lens-100k.csv\"  # replace with a name that you want to save the dataset under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download, Prepare, and Upload Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-02 13:49:01--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File ‘ml-100k.zip’ not modified on server. Omitting download.\n",
      "\n",
      "Archive:  ml-100k.zip\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       USER_ID  ITEM_ID  RATING  TIMESTAMP\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "...        ...      ...     ...        ...\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -N http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -o ml-100k.zip\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=['USER_ID', 'ITEM_ID', 'RATING', 'TIMESTAMP'])\n",
    "pd.set_option('display.max_rows', 5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare and Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['RATING'] > 3.6]                # keep only movies rated 3.6 and above\n",
    "data = data[['USER_ID', 'ITEM_ID', 'TIMESTAMP']] # select columns that match the columns in the schema below\n",
    "data.to_csv(filename, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createschema(schema, name):\n",
    "    \n",
    "    response = personalize.list_schemas(\n",
    "        maxResults=100\n",
    "    )\n",
    "\n",
    "    print(\"response: \", response)\n",
    "    \n",
    "    for item in response[\"schemas\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            return item[\"schemaArn\"]\n",
    "\n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name = name,\n",
    "        schema = json.dumps(schema)\n",
    "    )\n",
    "\n",
    "    schema_arn = create_schema_response['schemaArn']\n",
    "    #print(json.dumps(create_schema_response, indent=2))\n",
    "    return schema_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  {'schemas': [{'name': 'DEMO-schema', 'schemaArn': 'arn:aws:personalize:us-east-1:485483564801:schema/DEMO-schema', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 31, 53, 455000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 31, 53, 455000, tzinfo=tzlocal())}, {'name': 'aimlbootcamp-DEMO-schema', 'schemaArn': 'arn:aws:personalize:us-east-1:485483564801:schema/aimlbootcamp-DEMO-schema', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 52, 49, 340000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 52, 49, 340000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': 'cc60cb53-8350-40b5-afd5-4715735ad978', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Sat, 02 Nov 2019 13:49:03 GMT', 'x-amzn-requestid': 'cc60cb53-8350-40b5-afd5-4715735ad978', 'content-length': '385', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "{\n",
      "  \"schemaArn\": \"arn:aws:personalize:us-east-1:485483564801:schema/aimlbootcamp-schema-personalize-20191102\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"d9dc5ee0-dd77-42f7-8578-d341a766b4a3\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sat, 02 Nov 2019 13:49:03 GMT\",\n",
      "      \"x-amzn-requestid\": \"d9dc5ee0-dd77-42f7-8578-d341a766b4a3\",\n",
      "      \"content-length\": \"106\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n",
      "schema_arn:  arn:aws:personalize:us-east-1:485483564801:schema/aimlbootcamp-schema-personalize-20191102\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "schema_arn = createschema(schema, \"aimlbootcamp-schema-personalize-20191102\")\n",
    "print(\"schema_arn: \", schema_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Dataset Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdatasetGroup(name):\n",
    "    response = personalize.list_dataset_groups(\n",
    "        maxResults=100\n",
    "    )\n",
    "    print(\"response: \", response)\n",
    "    \n",
    "    for item in response[\"datasetGroups\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            return item[\"datasetGroupArn\"]\n",
    "    create_dataset_group_response = personalize.create_dataset_group(\n",
    "        name = name\n",
    "    )\n",
    "\n",
    "    dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "    #print(json.dumps(create_dataset_group_response, indent=2))   \n",
    "    return dataset_group_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  {'datasetGroups': [{'name': 'DEMO-dataset-group', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/DEMO-dataset-group', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 31, 53, 504000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 32, 22, 889000, tzinfo=tzlocal())}, {'name': 'aimldatasetgroupname', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/aimldatasetgroupname', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 2, 56, 51, 110000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 2, 57, 19, 831000, tzinfo=tzlocal())}, {'name': 'daniel', 'datasetGroupArn': 'arn:aws:personalize:us-east-1:485483564801:dataset-group/daniel', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 7, 7, 2, 39, 9, 916000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 7, 7, 2, 39, 30, 409000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': '37fdcb87-f742-41e4-ac8b-81ad04406ea0', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Sat, 02 Nov 2019 13:49:03 GMT', 'x-amzn-requestid': '37fdcb87-f742-41e4-ac8b-81ad04406ea0', 'content-length': '655', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "{\n",
      "  \"datasetGroupArn\": \"arn:aws:personalize:us-east-1:485483564801:dataset-group/aimlbootcamp-20191102\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"ee46e97e-994a-447f-ac40-0a06a6eb4a61\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sat, 02 Nov 2019 13:49:03 GMT\",\n",
      "      \"x-amzn-requestid\": \"ee46e97e-994a-447f-ac40-0a06a6eb4a61\",\n",
      "      \"content-length\": \"100\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n",
      "dataset_group_arn:  arn:aws:personalize:us-east-1:485483564801:dataset-group/aimlbootcamp-20191102\n"
     ]
    }
   ],
   "source": [
    "dataset_group_arn = createdatasetGroup(\"aimlbootcamp-20191102\")\n",
    "print(\"dataset_group_arn: \", dataset_group_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Group to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataset(name, dataset_type, dataset_group_arn, schema_arn):\n",
    "    response = personalize.list_datasets(\n",
    "        datasetGroupArn=dataset_group_arn,\n",
    "        maxResults=100\n",
    "    )\n",
    "    \n",
    "    #print(\"response: \", response)\n",
    "    for item in response[\"datasets\"]:\n",
    "        print(\"inspecting: \", item)\n",
    "        if item[\"name\"] == name or item[\"datasetType\"] == dataset_type:\n",
    "            #return item[\"datasetArn\"]\n",
    "            response = personalize.delete_dataset(\n",
    "                datasetArn=item[\"datasetArn\"]\n",
    "            )\n",
    "            max_time = time.time() + 2*60 # 10 minutes\n",
    "            while time.time() < max_time:\n",
    "                try:\n",
    "                    response = personalize.describe_dataset(datasetArn=item[\"datasetArn\"])\n",
    "                except Exception as e:\n",
    "                    if \"ResourceNotFoundException\".lower() in str(e).lower():\n",
    "                        print(\"delete completed\")\n",
    "                        break\n",
    "                except:\n",
    "                    raise\n",
    "                                    \n",
    "                status = response[\"dataset\"][\"status\"]\n",
    "                print(\"DatasetGroup: {}\".format(status))\n",
    "\n",
    "                time.sleep(5)\n",
    "            \n",
    "            \n",
    "    create_dataset_response = personalize.create_dataset(\n",
    "        name = name,\n",
    "        datasetType = dataset_type,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        schemaArn = schema_arn\n",
    "    )\n",
    "    print(\"dataset created....\")\n",
    "    dataset_arn = create_dataset_response['datasetArn']\n",
    "    #print(json.dumps(create_dataset_response, indent=2))\n",
    "    return dataset_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspecting:  {'name': 'aiml-bootcamp-dataset-20191102', 'datasetArn': 'arn:aws:personalize:us-east-1:485483564801:dataset/aimlbootcamp-20191102/INTERACTIONS', 'datasetType': 'INTERACTIONS', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 14, 11, 27, 823000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 14, 11, 27, 823000, tzinfo=tzlocal())}\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "DatasetGroup: DELETE PENDING\n",
      "delete completed\n",
      "dataset created....\n",
      "datasetarn:  arn:aws:personalize:us-east-1:485483564801:dataset/aimlbootcamp-20191102/INTERACTIONS\n"
     ]
    }
   ],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "dataset_arn = createdataset(\"aiml-bootcamp-dataset-20191102\", dataset_type, dataset_group_arn, schema_arn)\n",
    "\n",
    "\n",
    "print(\"datasetarn: \", dataset_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare, Create, and Wait for Dataset Import Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach Policy to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicyBootcamp\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicyAIMLBootcamp\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "policycreateresponse = s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Personalize Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPersonalizeIAMRole(role_name):\n",
    "    iam = boto3.client(\"iam\")\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "              },\n",
    "              \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "    #print(\"response: \", response)\n",
    "    #return\n",
    "    try:\n",
    "        create_role_response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "        )\n",
    "        role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "    except Exception as e:\n",
    "        if \"EntityAlreadyExists\".lower() in str(e).lower():\n",
    "            print(\"the role already exists!\")\n",
    "            response = iam.list_roles(\n",
    "                PathPrefix=\"/\",\n",
    "                MaxItems=1000\n",
    "            )\n",
    "            #print(\"all roles: \", response)\n",
    "            for item in response[\"Roles\"]:\n",
    "                if item[\"RoleName\"] == role_name:\n",
    "                    role_arn = item[\"Arn\"]\n",
    "                    break\n",
    "                    \n",
    "    except:\n",
    "        raise\n",
    "\n",
    "    # AmazonPersonalizeFullAccrole_arness provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "    # if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "    # that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "    policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "    iam.attach_role_policy(\n",
    "        RoleName = role_name,\n",
    "        PolicyArn = policy_arn\n",
    "    )\n",
    "    policy_arn = \"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    "    iam.attach_role_policy(\n",
    "        RoleName = role_name,\n",
    "        PolicyArn = policy_arn\n",
    "    )   \n",
    "    print(\"pausing execution to allow for IAM role propagation.....\")\n",
    "    time.sleep(30) # wait to allow IAM role policy attachment to propagate\n",
    "\n",
    "    return role_arn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the role already exists!\n",
      "pausing execution to allow for IAM role propagation.....\n",
      "arn:aws:iam::485483564801:role/PersonalizeRoleAIMLBootcamp-imports-1\n"
     ]
    }
   ],
   "source": [
    "role_name = \"PersonalizeRoleAIMLBootcamp-imports-2\"\n",
    "role_arn = createPersonalizeIAMRole(role_name)\n",
    "#json.dumps(create_dataset_response, indent=2)\n",
    "print(role_arn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset Import Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-1:485483564801:dataset-import-job/bootcamp-dataset-import-job-2\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"138fe748-766f-4b3d-9d98-5511e1610c8e\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Sat, 02 Nov 2019 15:16:55 GMT\",\n",
      "      \"x-amzn-requestid\": \"138fe748-766f-4b3d-9d98-5511e1610c8e\",\n",
      "      \"content-length\": \"117\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"bootcamp-dataset-import-job-2\",\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket, filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Dataset Import Job to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ***** 2019-11-02 15:20:53.867965  DatasetImportJob: ACTIVE                              \r"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "showme = \" \"\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(showme, datetime.datetime.now(), \" DatasetImportJob: {}\".format(status), \"             \", end='\\r')\n",
    "    showme += \"*\"\n",
    "    if len(showme)> 10:\n",
    "        showme = \" \"\n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(3.5719)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipes': [{'name': 'aws-hrnn',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-coldstart',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-coldstart',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-hrnn-metadata',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-hrnn-metadata',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-personalized-ranking',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-personalized-ranking',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-popularity-count',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-popularity-count',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 65000, tzinfo=tzlocal())},\n",
       "  {'name': 'aws-sims',\n",
       "   'recipeArn': 'arn:aws:personalize:::recipe/aws-sims',\n",
       "   'status': 'ACTIVE',\n",
       "   'creationDateTime': datetime.datetime(2019, 6, 10, 0, 0, tzinfo=tzlocal()),\n",
       "   'lastUpdatedDateTime': datetime.datetime(2019, 6, 20, 0, 39, 17, 64000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': '660570e9-8de1-4ac5-af43-d30fbf8f4c22',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sat, 02 Nov 2019 15:25:15 GMT',\n",
       "   'x-amzn-requestid': '660570e9-8de1-4ac5-af43-d30fbf8f4c22',\n",
       "   'content-length': '1067',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_recipes_response = personalize.list_recipes()\n",
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-hrnn\" # aws-hrnn selected for demo purposes\n",
    "list_recipes_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSolution(name, dataset_group_arn, recipe_arn):\n",
    "    response = personalize.list_solutions(\n",
    "        datasetGroupArn=dataset_group_arn,\n",
    "        maxResults=100\n",
    "    )\n",
    "    print(response)\n",
    "    for item in response[\"solutions\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            print(\"solution with the same name already exists. Deleting the existing one.\")\n",
    "            response = personalize.delete_solution(solutionArn=item[\"solutionArn\"])\n",
    "            \n",
    "            max_time = time.time() + 10*60 # 10 minutes\n",
    "            showme = \" \"\n",
    "            while time.time() < max_time:\n",
    "                response = personalize.describe_solution(solutionArn=item[\"solutionArn\"])\n",
    "                status = response[\"solution\"]['status']\n",
    "                print(showme, datetime.datetime.now(), \" solution: {}\".format(status), \"             \", end='\\r')\n",
    "                showme += \"*\"\n",
    "                if len(showme)> 10:\n",
    "                    showme = \" \"\n",
    "                if status == \"DELETED\":\n",
    "                    break\n",
    "\n",
    "                time.sleep(3.5719)\n",
    "            break\n",
    "    \n",
    "    create_solution_response = personalize.create_solution(\n",
    "        name = name,\n",
    "        datasetGroupArn = dataset_group_arn,\n",
    "        recipeArn = recipe_arn\n",
    "    )\n",
    "\n",
    "    solution_arn = create_solution_response['solutionArn']\n",
    "    print(json.dumps(create_solution_response, indent=2))\n",
    "    return solution_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solutions': [{'name': 'DEMO-solution', 'solutionArn': 'arn:aws:personalize:us-east-1:485483564801:solution/DEMO-solution', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 21, 26, 12, 120000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 21, 26, 12, 120000, tzinfo=tzlocal())}, {'name': 'aimlbootcampExampleSolution', 'solutionArn': 'arn:aws:personalize:us-east-1:485483564801:solution/aimlbootcampExampleSolution', 'status': 'ACTIVE', 'creationDateTime': datetime.datetime(2019, 11, 2, 21, 34, 23, 275000, tzinfo=tzlocal()), 'lastUpdatedDateTime': datetime.datetime(2019, 11, 2, 21, 34, 23, 275000, tzinfo=tzlocal())}], 'ResponseMetadata': {'RequestId': '6ee11582-73d6-4734-82f7-7b9fe141d689', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Sat, 02 Nov 2019 21:53:48 GMT', 'x-amzn-requestid': '6ee11582-73d6-4734-82f7-7b9fe141d689', 'content-length': '441', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "solution with the same name already exists. Deleting the existing one.\n",
      " ******* 2019-11-02 21:54:13.625154  solution: DELETE PENDING              \r"
     ]
    },
    {
     "ename": "ResourceNotFoundException",
     "evalue": "An error occurred (ResourceNotFoundException) when calling the DescribeSolution operation: The given solution does not exist: arn:aws:personalize:us-east-1:485483564801:solution/aimlbootcampExampleSolution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-7c26ad11345a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolution_arn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateSolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aimlbootcampExampleSolution\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_group_arn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe_arn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution_arn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-284-5f8389395cfe>\u001b[0m in \u001b[0;36mcreateSolution\u001b[0;34m(name, dataset_group_arn, recipe_arn)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mshowme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersonalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolutionArn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"solutionArn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"solution\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshowme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" solution: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"             \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceNotFoundException\u001b[0m: An error occurred (ResourceNotFoundException) when calling the DescribeSolution operation: The given solution does not exist: arn:aws:personalize:us-east-1:485483564801:solution/aimlbootcampExampleSolution"
     ]
    }
   ],
   "source": [
    "solution_arn = createSolution(\"aimlbootcampExampleSolution\", dataset_group_arn, recipe_arn)\n",
    "print(solution_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Solution Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Solution Version to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Metrics of Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Wait for Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"DEMO-campaign\",\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait for Campaign to Have ACTIVE Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select a User and an Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('./ml-100k/u.item', sep='|', usecols=[0,1], encoding='latin-1')\n",
    "items.columns = ['ITEM_ID', 'TITLE']\n",
    "\n",
    "user_id, item_id, _ = data.sample().values[0]\n",
    "item_title = items.loc[items['ITEM_ID'] == item_id].values[0][-1]\n",
    "print(\"USER: {}\".format(user_id))\n",
    "print(\"ITEM: {}\".format(item_title))\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GetRecommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    "    itemId = str(item_id)\n",
    ")\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "title_list = [items.loc[items['ITEM_ID'] == np.int(item['itemId'])].values[0][-1] for item in item_list]\n",
    "\n",
    "print(\"Recommendations: {}\".format(json.dumps(title_list, indent=2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
